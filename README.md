![image](https://github.com/user-attachments/assets/226aa4a0-bb22-4b92-aac7-525e5c407f36)# AIFFEL Data Scientist Campus Code Peer Review Templete

코더 : 한아영

리뷰어 : 조혜선

---

🔑 **PRT(Peer Review Template)**

[O]  **1. 주어진 문제를 해결하는 완성된 코드가 제출되었나요?**
- 문제에서 요구하는 최종 결과물이 첨부되었는지 확인
 1. 오버피팅 극복을 위하여 데이터셋의 다양성, 정규화 등을 2가지 이상 시도해보았음
	- 데이터를 300개에서 3000개로 늘려보는 시도를 했습니다.
 		- ![image](https://github.com/user-attachments/assets/e92a5cc4-5e6c-4672-a7ee-8c652f8f82bd)
	- 정규화를 시도했습니다.
 		- ![image](https://github.com/user-attachments/assets/881bcb74-906e-4497-a5ad-f8b385747fed)
 2. 분류모델의 test accuracy가 85% 이상 높게 나왔는가?
	- loss 가 높긴 하지만 테스트셋 성능이 94.3%를 달성했습니다.
 		- ![image](https://github.com/user-attachments/assets/e3eba327-26ea-4c80-a376-a163b158b421)


[O]  **2. 전체 코드에서 가장 핵심적이거나 가장 복잡하고 이해하기 어려운 부분에 작성된 
	주석 또는 doc string을 보고 해당 코드가 잘 이해되었나요?**
- 해당 코드 블럭에 doc string/annotation이 달려 있는지 확인
- 해당 코드가 무슨 기능을 하는지, 왜 그렇게 짜여진건지, 작동 메커니즘이 뭔지 기술.
- 주석을 보고 코드 이해가 잘 되었는지 확인
	- ![image](https://github.com/user-attachments/assets/77946d88-5269-486c-9cec-c470b8d076e9)


[O]  **3. 에러가 난 부분을 디버깅하여 문제를 “해결한 기록"을 남겼거나 "새로운 시도 
또는 추가 실험"을 수행해봤나요?**
- 문제 원인 및 해결 과정을 잘 기록하였는지 확인 또는
- 문제에서 요구하는 조건에 더해 추가적으로 수행한 나만의 시도, 실험이 기록되어 있는지 확인
	- 데이터를 늘려보는 노력을 통해 성능을 향상 시켰습니다. 
 	- ![image](https://github.com/user-attachments/assets/9d79d0b1-2e8a-4662-847e-89d59e56e113)

        
[X]  **4. 회고를 잘 작성했나요?**
- 주어진 문제를 해결하는 완성된 코드 내지 프로젝트 결과물에 대해 배운점과 아쉬운점, 느낀점 등이 상세히 기록되어 있는지 확인
    - 딥러닝 모델의 경우, 인풋이 들어가 최종적으로 아웃풋이 나오기까지의 전체 흐름을 도식화하여 모델 아키텍쳐에 대한 이해를 돕고 있는지 확인
	- 회고는 없었습니다. 
	- 전체 흐름에 대한 도식화는 없었습니다. 


[X]  **5. 코드가 간결하고 효율적인가요?**
- 파이썬 스타일 가이드 (PEP8) 를 준수하였는지 확인
- 코드 중복을 최소화하고 범용적으로 사용할 수 있도록 모듈화(함수화) 했는지
	- 기존 커리큘럼의 코드가 주어진 스타일로 중복되는 코드가 반복적으로 사용한 부분들이 있었니다. 

---
### 참고 문헌
